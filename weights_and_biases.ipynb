{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "###### Follow the instructions given in comments prefixed with ## and write your code below that.\n",
    "###### Also fill the partial code in given blanks. \n",
    "###### Don't make any changes to the rest part of the codes\n",
    "\n",
    "### Answer the questions given at the end of this notebook within your report.\n",
    "\n",
    "\n",
    "### You would need to submit your GitHub repository link. Refer to the Section 6: Final Submission on the PDF document for the details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import cv2\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"37266670017b773ce7eec39baeb3a5fedee3aadd\")\n",
    "import sys\n",
    "\n",
    "# Redirect output to a file\n",
    "sys.stdout = open(\"Metrics-and-logs.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Reading the image plaksha_Faculty.jpg\n",
    "faculty_img = cv2.imread(\"Plaksha_Faculty.jpg\")\n",
    "shashu_img = cv2.imread(\"Dr_Shashi_Tharoor.jpg\")\n",
    "\n",
    "## Convert the image to grayscale\n",
    "gray_faculty=cv2.cvtColor(faculty_img, cv2.COLOR_BGR2GRAY)\n",
    "gray_shashu=cv2.cvtColor(shashu_img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Loading the required haar-cascade xml classifier file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "  \n",
    "# Applying the face detection method on the grayscale image. \n",
    "## Change the parameters for better detection of faces in your case.\n",
    "faces_rect = face_cascade.detectMultiScale(gray_faculty, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    "shashu_face=face_cascade.detectMultiScale(gray_shashu,1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    "\n",
    "# Define the text and font parameters\n",
    "text = \"Gotchya\" ## The text you want to write\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX ## Font type\n",
    "font_scale = 0.5 ## Font scale factor\n",
    "font_color = (0, 0, 255) ## Text color in BGR format (here, it's red)\n",
    "font_thickness =  2 # Thickness of the text\n",
    "  \n",
    "# Iterating through rectangles of detected faces\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(faculty_img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    # Use cv2.putText to add the text to the image, Use text, font, font_scale, font_color, font_thickness here\n",
    "    cv2.putText(faculty_img, text, (x, y - 10), font, font_scale, font_color, font_thickness)\n",
    "    \n",
    "## Display the image and window title should be \"Total number of face detected are #\"  \n",
    "cv2.imshow(f\"Total number of faces detected are {faces_rect}\", faculty_img)\n",
    "# cv2.waitKey(5000)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Extract face region features (Hue and Saturation)\n",
    "img_hsv = cv2.cvtColor(shashu_img, cv2.COLOR_BGR2HSV)  ## Convert image from BGR to HSV\n",
    "hue_saturation = []\n",
    "face_images = []  # To store detected face images\n",
    "\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    face = img_hsv[y:y + h, x:x + w]\n",
    "    \n",
    "    # Skip empty face regions\n",
    "    if face.size == 0:\n",
    "        print(f\"Skipping empty face region at ({x}, {y}, {w}, {h})\")\n",
    "        continue\n",
    "    \n",
    "    hue = np.mean(face[:, :, 0])\n",
    "    saturation = np.mean(face[:, :, 1])\n",
    "    \n",
    "    # Skip NaN values\n",
    "    if np.isnan(hue) or np.isnan(saturation):\n",
    "        print(f\"Skipping face with NaN hue/saturation at ({x}, {y}, {w}, {h})\")\n",
    "        continue\n",
    "\n",
    "    hue_saturation.append((hue, saturation))\n",
    "    face_images.append(face)\n",
    "\n",
    "hue_saturation = np.array(hue_saturation)\n",
    "\n",
    "# Check if we have enough valid face data to cluster\n",
    "\n",
    "if len(hue_saturation)==0:\n",
    "    print(\"No valid face regions to cluster(ghosts)\")\n",
    "    exit()\n",
    "\n",
    "# Perform k-Means clustering on valid hue_saturation data\n",
    "kmeans = KMeans(n_clusters=min(2, len(hue_saturation)), random_state=42).fit(hue_saturation)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Only plot faces that were successfully processed\n",
    "valid_faces = min(len(face_images), len(hue_saturation))\n",
    "\n",
    "for i in range(valid_faces):\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color='red' if kmeans.labels_[i] == 0 else 'blue')\n",
    "\n",
    "## Add plot labels\n",
    "plt.xlabel('Hue')\n",
    "plt.ylabel('Saturation')\n",
    "plt.title('Clustered Faces Based on Hue and Saturation')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.savefig(\"clustered_faces.png\")\n",
    "\n",
    "# Let me know if youâ€™d like any adjustments or explanations! ðŸš€\n",
    "print(len(faces_rect))\n",
    "print(len(kmeans.labels_))\n",
    "print(len(hue_saturation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i in range(len(kmeans.labels_)):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "\n",
    "cluster_0_points = np.array(cluster_0_points)\n",
    "# Plot points for cluster 0 in green\n",
    "plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], color='green', label='Cluster 0')\n",
    "\n",
    "cluster_1_points = np.array(cluster_1_points)\n",
    "# Plot points for cluster 1 in blue\n",
    "plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], color='blue', label='Cluster 1')\n",
    "\n",
    "# Calculate and plot centroids\n",
    "centroid_0 = kmeans.cluster_centers_[0]\n",
    "centroid_1 = kmeans.cluster_centers_[1]\n",
    "\n",
    "# Plot both the centroid for cluster 0 and cluster 1 \n",
    "plt.scatter(centroid_0[0], centroid_0[1], c='yellow', marker='X', s=200, label='Centroid 0')\n",
    "plt.scatter(centroid_1[0], centroid_1[1], c='purple', marker='X', s=200, label='Centroid 1')\n",
    "\n",
    "plt.xlabel('Hue')\n",
    "plt.ylabel('Saturation')\n",
    "plt.title('Clusters with Centroids')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.savefig(\"clustered_faces_with_centroids.png\")\n",
    "\n",
    "## Put x label\n",
    "## Put y label\n",
    "## Put title\n",
    "## Add a legend\n",
    "## Add grid\n",
    "## Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read the class of the template image 'Dr_Shashi_Tharoor.jpg' using cv2 and store it in template_img\n",
    "template_img = cv2.imread('Dr_Shashi_Tharoor.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_template = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect face in the template image and store it in template_faces\n",
    "template_faces = face_cascade.detectMultiScale(gray_template, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in template_faces:\n",
    "    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "# Display the image with detected faces\n",
    "cv2.imshow('Gotchya', template_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the template image to HSV color space and store it in template_hsv\n",
    "template_img = shashu_img\n",
    "template_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Extract hue and saturation features from the template image as we did it for detected faces.\n",
    "template_hue = np.mean(template_hsv[:, :, 0])\n",
    "template_saturation = np.mean(template_hsv[:, :, 1])\n",
    "\n",
    "# Predict the cluster label for the template image and store it in template_label\n",
    "template_label = kmeans.predict([[template_hue, template_saturation]])[0]\n",
    "\n",
    "# Create a figure and axis for visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Only iterate through valid detected faces\n",
    "valid_faces = min(len(faces_rect), len(kmeans.labels_))\n",
    "\n",
    "for i in range(valid_faces):\n",
    "    color = 'red' if kmeans.labels_[i] == 0 else 'blue'\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color=color)\n",
    "\n",
    "# Plot the template image in the respective cluster\n",
    "if not np.isnan(template_hue) and not np.isnan(template_saturation):\n",
    "    color = 'red' if template_label == 0 else 'blue'\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(template_img, (20, 20)), cv2.COLOR_BGR2RGB))\n",
    "    ab = AnnotationBbox(im, (template_hue, template_saturation), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "plt.xlabel('Hue')\n",
    "plt.ylabel('Saturation')\n",
    "plt.title('Template Image Classification within Clusters')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.savefig(\"template_image_classification.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Only iterate through valid detected faces\n",
    "valid_faces = min(len(faces_rect), len(kmeans.labels_), len(hue_saturation))\n",
    "\n",
    "for i in range(valid_faces):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "# Plot points for cluster 0 in green\n",
    "if len(cluster_0_points) > 0:\n",
    "    cluster_0_points = np.array(cluster_0_points)\n",
    "    plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], color='green', label='Cluster 0')\n",
    "\n",
    "# Plot points for cluster 1 in blue\n",
    "if len(cluster_1_points) > 0:\n",
    "    cluster_1_points = np.array(cluster_1_points)\n",
    "    plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], color='blue', label='Cluster 1')\n",
    "# Calculate and plot centroids for both the clusters\n",
    "if len(kmeans.cluster_centers_) >= 2:\n",
    "    centroid_0 = kmeans.cluster_centers_[0]\n",
    "    centroid_1 = kmeans.cluster_centers_[1]\n",
    "    plt.scatter(centroid_0[0], centroid_0[1], c='yellow', marker='X', s=200, label='Centroid 0')\n",
    "    plt.scatter(centroid_1[0], centroid_1[1], c='purple', marker='X', s=200, label='Centroid 1')\n",
    "\n",
    "# Plot the template point if valid\n",
    "if not np.isnan(template_hue) and not np.isnan(template_saturation):\n",
    "    plt.plot(template_hue, template_saturation, marker='o', c='violet', markersize=10, label='Class ?')\n",
    "\n",
    "plt.xlabel('Hue')\n",
    "plt.ylabel('Saturation')\n",
    "plt.title('Template Classification within Clusters')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"template_classification_within_clusters.png\")\n",
    "## End of the lab 5 ##\n",
    "\n",
    "# Restore normal stdout\n",
    "sys.stdout.close()\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "print(\"Output saved to output.txt\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6741855,
     "sourceId": 10854316,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
